"""Functions for systematically evaluating a function over all combinations.
"""
# TODO: allow combo_runner_to_ds to use output vars as coords --------------- #

import itertools

import xarray as xr
import numpy as np
from dask.delayed import delayed, compute

from ..utils import _parse_fn_name, prod, progbar, update_upon_eval, unzip
from ..parallel import _dask_get, DaskTqdmProgbar


def _parse_combos(combos):
    """Turn dicts and single tuples into proper form for combo runners.
    """
    if isinstance(combos, dict):
        return tuple(combos.items())
    elif isinstance(combos[0], str):
        return (combos,)
    return tuple(combos)


def _nested_submit(fn, combos, kwds, delay=False):
    """Recursively submit jobs.
    """
    arg, inputs = combos[0]
    if len(combos) == 1:
        if delay:
            return [delayed(fn)(**kwds, **{arg: x}) for x in inputs]
        else:
            return [fn(**kwds, **{arg: x}) for x in inputs]
    else:
        return [_nested_submit(fn, combos[1:], {**kwds, arg: x}, delay=delay)
                for x in inputs]


def combo_runner(fn, combos, constants=None,
                 split=False,
                 parallel=False,
                 parallel_backend=None,
                 num_workers=None,
                 hide_progbar=False,
                 progbar_opts=None):
    """Take a function fn and analyse it over all combinations of named
    variables' values, optionally showing progress and in parallel.

    Parameters
    ----------
        fn: callable
            Function to analyse
        combos: mapping of individual fn arguments to iterable of values
            All combinations of each argument will be calculated. Each
            argument range thus gets a dimension in the output array(s).
        constants:
            List of tuples/dict of *constant* fn argument mappings.
        split:
            Whether to split into multiple output arrays or not.
        hide_progbar:
            Whether to disable the progress bar.
        parallel: bool
            Process combos in parallel, default number of workers picked.
        num_workers: int
            Explicitly choose how many workers to use, None for automatic.
        progbar_opts: dict
            Options for the progress bar.

    Returns
    -------
        data:
            list of result arrays, each with all param combinations in nested
            tuples.
    """
    # Prepare combos
    combos = _parse_combos(combos)
    fn_name = _parse_fn_name(fn)

    constants = dict() if constants is None else dict(constants)
    progbar_opts = dict() if progbar_opts is None else dict(progbar_opts)

    # Evaluate combos in parallel ------------------------------------------- #
    if parallel or num_workers:
        with DaskTqdmProgbar(fn_name, disable=hide_progbar, **progbar_opts):
            jobs = _nested_submit(fn, combos, constants, delay=True)
            getter = (_dask_get(parallel_backend, num_workers=num_workers) if
                      parallel_backend is not None else None)
            results = compute(*jobs, get=getter, num_workers=num_workers)

    # Evaluate combos sequentially ------------------------------------------ #
    else:
        n = prod(len(x[1]) for x in combos)
        with progbar(total=n, disable=hide_progbar, **progbar_opts) as p:
            fn = update_upon_eval(fn, p)
            results = _nested_submit(fn, combos, constants)

    return list(unzip(results, len(combos))) if split else results


def combos_to_ds(results, combos, var_names,
                 var_dims=None,
                 var_coords=None,
                 constants=None,
                 attrs=None):
    """Convert the output of combo_runner into a `xarray.Dataset`

    Parameters
    ----------
        results: array(s) of dimension `len(combos)`
        combos: list of tuples of form ((variable_name, [values]), ...) with
            which `results` was generated.
        var_names: name(s) of output variables for a single result
        var_dims: the list of named coordinates for each single result
            variable, i.e. coordinates not generated by the combo_runner
        var_coords: dict of values for those coordinates if custom ones are
            desired.

    Returns
    -------
        ds: xarray Dataset with appropriate coordinates.
    """
    combos = _parse_combos(combos)
    fn_args, _ = zip(*combos)

    # Work out if multiple variables are expected as output
    if isinstance(var_names, str):
        var_names = (var_names,)
        results = (results,)
        if var_dims is not None:
            var_dims = (var_dims,)
    elif len(var_names) == 1:
        results = (results,)

    # Allow single given dimensions to represent all result variables
    var_dims = (itertools.cycle(var_dims) if var_dims is not None else
                itertools.repeat(tuple()))

    var_coords = dict(var_coords) if var_coords is not None else dict()

    # Set dataset coordinates
    ds = xr.Dataset(coords={**dict(combos), **dict(var_coords)},
                    data_vars={vname: (tuple(fn_args) + tuple(vdims),
                                       np.asarray(vdata))
                               for vdata, vname, vdims in zip(results,
                                                              var_names,
                                                              var_dims)},
                    attrs=attrs)

    # TODO: merge into add_to_ds

    # Add non-coordinate constants to attrs
    if constants is not None:
        for constant, value in constants.items():
            if constant not in ds.coords:
                ds.attrs[constant] = value

    return ds


def combo_runner_to_ds(fn, combos, var_names,
                       var_dims=None,
                       var_coords=None,
                       constants=None,
                       resources=None,
                       attrs=None,
                       **combo_runner_settings):
    """Evaluate a function over all combinations and output to a Dataset.

    Parameters
    ----------
        fn: callable
            Function to evaluate.

        combos: mapping
            Mapping of each individual function argument to iterable of values.

        var_names: str or iterable of strings
            Variable name(s) of the output(s) of `fn`.

        var_dims: iterable of strings or iterable of iterable of strings
            'Internal' names of dimensions for each variable, the values for
            each dimension should be contiained as a mapping in either
            `var_coords` (not needed by `fn`) or `constants` (needed by `fn`).

        var_coords: mapping
            Mapping of extra coords the output variables may depend on.

        constants: mapping
            Arguments to `fn` which are not iterated over, these will be
            recorded either as attributes or coordinates if they are used.

        resources: mapping
            Like `constants` but they will not be recorded.

        attrs: mapping
            Any extra attributes to store.

        **combo_runner_settings: dict-like
            Arguments supplied to `combo_runner`.

    Returns
    -------
        xarray.Dataset
    """
    # Parse inputs
    var_coords = dict(var_coords) if var_coords is not None else dict()
    constants = dict(constants) if constants is not None else dict()
    resources = dict(resources) if resources is not None else dict()

    # Set split based on output var_names
    split = (False if isinstance(var_names, str) else
             False if len(var_names) == 1 else True)

    # Generate data for all combos
    results = combo_runner(fn, combos, split=split,
                           constants={**resources, **constants},
                           **combo_runner_settings)
    # Convert to dataset
    ds = combos_to_ds(results, combos,
                      var_names=var_names,
                      var_dims=var_dims,
                      var_coords=var_coords,
                      constants=constants,
                      attrs=attrs)
    return ds
